# ë¼ë²¨ ì—†ì´ ëª¨ë¸ ì •í™•ë„ í‰ê°€í•˜ëŠ” ë°©ë²•

## ë¬¸ì œ ì •ì˜

**í˜„ì¬ í‰ê°€ ë°©ì‹**:
```python
# labelled_simpson.jsonl í•„ìš”
python tools/model_evaluator.py \
    --video assets/simpson.mp4 \
    --labels labelled_simpson.jsonl \
    --disable-text
```

**ë¬¸ì œì **:
- ë¼ë²¨ë§ ì‘ì—… ì‹œê°„ ì†Œìš” (1ì‹œê°„+)
- ìƒˆë¡œìš´ ì˜ìƒë§ˆë‹¤ ìˆ˜ë™ ë¼ë²¨ë§ í•„ìš”
- ì£¼ê´€ì  íŒë‹¨ (ë¼ë²¨ëŸ¬ë§ˆë‹¤ ë‹¤ë¦„)

**ëª©í‘œ**:
ë¼ë²¨ ì—†ì´ë„ ëª¨ë¸ì˜ í’ˆì§ˆì„ ì •ëŸ‰ì /ì •ì„±ì ìœ¼ë¡œ í‰ê°€

---

## âœ… ë°©ë²• 1: Cross-Model Consistency (ëª¨ë¸ ê°„ ì¼ì¹˜ë„)

### ì›ë¦¬
ì—¬ëŸ¬ ëª¨ë¸ì´ ê°™ì€ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ **ì¼ì¹˜í•˜ëŠ” ì˜ˆì¸¡**ì„ í•  ê²½ìš°, ë†’ì€ ì‹ ë¢°ë„ë¡œ ê°„ì£¼

### êµ¬í˜„ ë°©ë²•

#### Step 1: ë‹¤ì¤‘ ëª¨ë¸ ì˜ˆì¸¡

```python
# 3ê°œ ì´ìƒì˜ ëª¨ë¸ë¡œ ë™ì¼í•œ ì˜ìƒ ì˜ˆì¸¡
models = [
    'superb/wav2vec2-large-superb-er',
    'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition',
    'speechbrain/emotion-recognition-wav2vec2-IEMOCAP'
]

predictions = {}
for model_name in models:
    classifier = EmotionClassifier(audio_model_name=model_name)
    predictions[model_name] = classifier.classify_batch(segments)
```

#### Step 2: ì¼ì¹˜ë„ ê³„ì‚°

```python
def calculate_consistency(predictions):
    """ëª¨ë¸ ê°„ ì˜ˆì¸¡ ì¼ì¹˜ë„ ê³„ì‚°"""
    n_segments = len(predictions[list(predictions.keys())[0]])
    consistency_scores = []
    
    for i in range(n_segments):
        # ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡
        segment_predictions = [
            predictions[model][i]['emotion'] 
            for model in predictions
        ]
        
        # ê°€ì¥ ë§ì´ ì˜ˆì¸¡ëœ ê°ì •
        from collections import Counter
        most_common = Counter(segment_predictions).most_common(1)[0]
        agreement_ratio = most_common[1] / len(predictions)
        
        consistency_scores.append({
            'segment_id': i,
            'consensus_emotion': most_common[0],
            'agreement': agreement_ratio,
            'predictions': segment_predictions
        })
    
    return consistency_scores
```

#### Step 3: í’ˆì§ˆ ì§€í‘œ

```python
# 1. í‰ê·  ì¼ì¹˜ë„
avg_consistency = np.mean([s['agreement'] for s in consistency_scores])

# 2. ê³ ì‹ ë¢° ì„¸ê·¸ë¨¼íŠ¸ ë¹„ìœ¨ (80% ì´ìƒ ì¼ì¹˜)
high_confidence_ratio = sum(
    1 for s in consistency_scores if s['agreement'] >= 0.8
) / len(consistency_scores)

# 3. ê°ì • ë¶„í¬ ë‹¤ì–‘ì„± (Shannon Entropy)
from scipy.stats import entropy
emotion_counts = Counter([s['consensus_emotion'] for s in consistency_scores])
emotion_probs = [count / len(consistency_scores) for count in emotion_counts.values()]
diversity = entropy(emotion_probs)
```

### í‰ê°€ ê¸°ì¤€

| ì§€í‘œ | ì¢‹ì€ ëª¨ë¸ | ë‚˜ìœ ëª¨ë¸ |
|------|-----------|-----------|
| í‰ê·  ì¼ì¹˜ë„ | > 0.6 | < 0.4 |
| ê³ ì‹ ë¢° ë¹„ìœ¨ | > 50% | < 30% |
| ë‹¤ì–‘ì„± (Entropy) | 1.5~2.0 | < 1.0 (ì¤‘ë¦½ í¸í–¥) |

### ì¥ì 
- âœ… ë¼ë²¨ë§ ë¶ˆí•„ìš”
- âœ… ì •ëŸ‰ì  ì§€í‘œ ì œê³µ
- âœ… ì´ìƒê°’ íƒì§€ (ì¼ì¹˜ë„ ë‚®ì€ ì„¸ê·¸ë¨¼íŠ¸)

### ë‹¨ì 
- âŒ ëª¨ë“  ëª¨ë¸ì´ í‹€ë¦´ ìˆ˜ ìˆìŒ (ì§‘ë‹¨ í¸í–¥)
- âŒ ìµœì†Œ 3ê°œ ì´ìƒ ëª¨ë¸ í•„ìš”

---

## âœ… ë°©ë²• 2: Confidence Distribution Analysis (ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„)

### ì›ë¦¬
ì¢‹ì€ ëª¨ë¸ì€ **ëª…í™•í•œ ì˜ˆì¸¡** (ë†’ì€ confidence)ê³¼ **ê°ì • ë‹¤ì–‘ì„±**ì„ ë³´ì„

### êµ¬í˜„ ë°©ë²•

#### Step 1: ì‹ ë¢°ë„ í†µê³„

```python
def analyze_confidence(predictions):
    """ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„"""
    confidences = [p['confidence'] for p in predictions]
    
    metrics = {
        'mean_confidence': np.mean(confidences),
        'median_confidence': np.median(confidences),
        'std_confidence': np.std(confidences),
        'min_confidence': np.min(confidences),
        'max_confidence': np.max(confidences),
        
        # ê³ ì‹ ë¢° ì˜ˆì¸¡ ë¹„ìœ¨ (> 0.7)
        'high_confidence_ratio': sum(1 for c in confidences if c > 0.7) / len(confidences),
        
        # ì €ì‹ ë¢° ì˜ˆì¸¡ ë¹„ìœ¨ (< 0.4)
        'low_confidence_ratio': sum(1 for c in confidences if c < 0.4) / len(confidences)
    }
    
    return metrics
```

#### Step 2: ê°ì • ë¶„í¬ ë¶„ì„

```python
def analyze_emotion_distribution(predictions):
    """ê°ì • ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„"""
    from collections import Counter
    
    emotion_counts = Counter([p['emotion'] for p in predictions])
    total = len(predictions)
    
    distribution = {
        emotion: count / total 
        for emotion, count in emotion_counts.items()
    }
    
    # ì¤‘ë¦½ ë¹„ìœ¨ ì²´í¬
    neutral_ratio = distribution.get('neutral', 0)
    
    # ë‹¤ì–‘ì„± (Entropy)
    from scipy.stats import entropy
    diversity = entropy(list(distribution.values()))
    
    # Gini ê³„ìˆ˜ (ë¶ˆê· í˜• ì¸¡ì •, 0=ì™„ì „ ê· ë“±, 1=ì™„ì „ ë¶ˆê· ë“±)
    sorted_probs = sorted(distribution.values())
    n = len(sorted_probs)
    gini = sum((2 * i - n - 1) * p for i, p in enumerate(sorted_probs, 1)) / (n * sum(sorted_probs))
    
    return {
        'distribution': distribution,
        'neutral_ratio': neutral_ratio,
        'diversity': diversity,
        'gini_coefficient': gini,
        'dominant_emotion': max(distribution, key=distribution.get),
        'dominant_ratio': max(distribution.values())
    }
```

### í‰ê°€ ê¸°ì¤€

#### ì¢‹ì€ ëª¨ë¸
- **í‰ê·  ì‹ ë¢°ë„**: 0.6~0.8 (ë„ˆë¬´ ë†’ìœ¼ë©´ ê³¼ì‹ ë¢°)
- **ê³ ì‹ ë¢° ë¹„ìœ¨**: 40~60%
- **ì¤‘ë¦½ ë¹„ìœ¨**: 20~40% (ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¹„í˜„ì‹¤ì )
- **ë‹¤ì–‘ì„± (Entropy)**: 1.5~2.0
- **Gini ê³„ìˆ˜**: 0.2~0.5 (ì ë‹¹í•œ ë¶ˆê· í˜•)

#### ë‚˜ìœ ëª¨ë¸
- í‰ê·  ì‹ ë¢°ë„ < 0.4 (ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡)
- ì¤‘ë¦½ ë¹„ìœ¨ > 70% (ì¤‘ë¦½ í¸í–¥)
- ë‹¤ì–‘ì„± < 1.0 (í•œë‘ ê°ì •ë§Œ ì˜ˆì¸¡)
- Gini ê³„ìˆ˜ > 0.8 (ê·¹ë‹¨ì  ë¶ˆê· í˜•)

### ì‹œê°í™”

```python
import matplotlib.pyplot as plt

def visualize_model_quality(predictions):
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. ì‹ ë¢°ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    confidences = [p['confidence'] for p in predictions]
    axes[0, 0].hist(confidences, bins=20, edgecolor='black')
    axes[0, 0].set_title('Confidence Distribution')
    axes[0, 0].set_xlabel('Confidence')
    axes[0, 0].set_ylabel('Count')
    
    # 2. ê°ì • ë¶„í¬ ë°” ì°¨íŠ¸
    emotion_dist = analyze_emotion_distribution(predictions)['distribution']
    axes[0, 1].bar(emotion_dist.keys(), emotion_dist.values())
    axes[0, 1].set_title('Emotion Distribution')
    axes[0, 1].set_ylabel('Ratio')
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # 3. ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹ ë¢°ë„ ë³€í™”
    axes[1, 0].plot(confidences)
    axes[1, 0].axhline(y=0.7, color='g', linestyle='--', label='High Conf')
    axes[1, 0].axhline(y=0.4, color='r', linestyle='--', label='Low Conf')
    axes[1, 0].set_title('Confidence over Segments')
    axes[1, 0].set_xlabel('Segment Index')
    axes[1, 0].set_ylabel('Confidence')
    axes[1, 0].legend()
    
    # 4. ê°ì • ì „í™˜ ë¹ˆë„ (Transition Matrix)
    emotions = [p['emotion'] for p in predictions]
    transitions = {}
    for i in range(len(emotions) - 1):
        key = (emotions[i], emotions[i+1])
        transitions[key] = transitions.get(key, 0) + 1
    
    # ì „í™˜ í–‰ë ¬ ì‹œê°í™” (ê°„ë‹¨íˆ)
    unique_emotions = sorted(set(emotions))
    matrix = np.zeros((len(unique_emotions), len(unique_emotions)))
    for i, e1 in enumerate(unique_emotions):
        for j, e2 in enumerate(unique_emotions):
            matrix[i, j] = transitions.get((e1, e2), 0)
    
    axes[1, 1].imshow(matrix, cmap='YlOrRd')
    axes[1, 1].set_xticks(range(len(unique_emotions)))
    axes[1, 1].set_yticks(range(len(unique_emotions)))
    axes[1, 1].set_xticklabels(unique_emotions, rotation=45)
    axes[1, 1].set_yticklabels(unique_emotions)
    axes[1, 1].set_title('Emotion Transition Matrix')
    
    plt.tight_layout()
    plt.savefig('model_quality_report.png')
    plt.show()
```

---

## âœ… ë°©ë²• 3: Entropy-Based Quality Score (ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜)

### ì›ë¦¬
ëª¨ë¸ì˜ ì˜ˆì¸¡ ë¶„í¬ê°€ **ë„ˆë¬´ í™•ì‹ ì ì´ê±°ë‚˜ ë„ˆë¬´ ë¶ˆí™•ì‹¤í•˜ì§€ ì•Šì€ ì ì • ìˆ˜ì¤€**ì„ ìœ ì§€

### êµ¬í˜„

```python
def calculate_entropy_score(predictions):
    """ê° ì˜ˆì¸¡ì˜ ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜"""
    from scipy.stats import entropy
    
    scores = []
    for pred in predictions:
        # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ ê°ì • ë¶„í¬ (audio_distribution)
        dist = pred['audio_distribution']
        probs = list(dist.values())
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (0=í™•ì‹¤, 2.8=ì™„ì „ ë¶ˆí™•ì‹¤ for 7 emotions)
        ent = entropy(probs, base=2)
        
        # ì´ìƒì  ì—”íŠ¸ë¡œí”¼: 1.0~2.0
        # ë„ˆë¬´ ë‚®ìœ¼ë©´ ê³¼ì‹ ë¢°, ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶ˆí™•ì‹¤
        if 1.0 <= ent <= 2.0:
            quality = 1.0
        elif ent < 1.0:
            quality = ent / 1.0  # 0~1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼
        else:
            quality = 2.0 / ent  # 2.0 ì´ìƒì€ íŒ¨ë„í‹°
        
        scores.append({
            'segment_id': pred.get('segment_id', 0),
            'entropy': ent,
            'quality_score': quality,
            'emotion': pred['emotion'],
            'confidence': pred['confidence']
        })
    
    avg_quality = np.mean([s['quality_score'] for s in scores])
    return avg_quality, scores
```

### í‰ê°€ ê¸°ì¤€

| í‰ê·  í’ˆì§ˆ ì ìˆ˜ | íŒë‹¨ |
|---------------|------|
| > 0.8 | ìš°ìˆ˜ (ì ì ˆí•œ í™•ì‹ ë„) |
| 0.6~0.8 | ì–‘í˜¸ |
| 0.4~0.6 | ë³´í†µ (ê°œì„  í•„ìš”) |
| < 0.4 | ë¶ˆëŸ‰ (ê·¹ë‹¨ì  ì˜ˆì¸¡) |

---

## âœ… ë°©ë²• 4: Perceptual Validation (ì§€ê°ì  ê²€ì¦)

### ì›ë¦¬
ì¸ê°„ì´ **ìƒ˜í”Œë§ëœ ê²°ê³¼**ë¥¼ ë¹ ë¥´ê²Œ ê²€í† í•˜ì—¬ ì •ì„±ì  í‰ê°€

### êµ¬í˜„

#### Step 1: ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ

```python
def select_representative_samples(predictions, n_samples=10):
    """ê° ê°ì •ë³„ ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ"""
    from collections import defaultdict
    
    by_emotion = defaultdict(list)
    for i, pred in enumerate(predictions):
        by_emotion[pred['emotion']].append((i, pred))
    
    samples = []
    for emotion, preds in by_emotion.items():
        # ê° ê°ì •ì—ì„œ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ìƒ˜í”Œ ì„ íƒ
        sorted_preds = sorted(preds, key=lambda x: x[1]['confidence'], reverse=True)
        top_sample = sorted_preds[0] if sorted_preds else None
        if top_sample:
            samples.append({
                'segment_index': top_sample[0],
                'emotion': emotion,
                'confidence': top_sample[1]['confidence'],
                'start': predictions[top_sample[0]].get('start', 0),
                'end': predictions[top_sample[0]].get('end', 0)
            })
    
    return samples
```

#### Step 2: ë¦¬ë·° ì¸í„°í˜ì´ìŠ¤

```python
def generate_review_html(video_path, samples, output_html='review.html'):
    """HTML ê¸°ë°˜ ë¦¬ë·° ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    html = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Model Prediction Review</title>
        <style>
            .sample { margin: 20px; padding: 10px; border: 1px solid #ccc; }
            video { width: 640px; }
        </style>
    </head>
    <body>
        <h1>ëª¨ë¸ ì˜ˆì¸¡ ìƒ˜í”Œ ê²€í† </h1>
    """
    
    for sample in samples:
        html += f"""
        <div class="sample">
            <h3>ê°ì •: {sample['emotion']} (ì‹ ë¢°ë„: {sample['confidence']:.2f})</h3>
            <p>ì‹œê°„: {sample['start']:.1f}s - {sample['end']:.1f}s</p>
            <video controls>
                <source src="{video_path}#t={sample['start']},{sample['end']}" type="video/mp4">
            </video>
            <p>
                <label>ì •í™•í•¨: <input type="checkbox" name="correct_{sample['segment_index']}"></label>
                <label>ë¶€ì •í™•í•¨: <input type="checkbox" name="incorrect_{sample['segment_index']}"></label>
            </p>
        </div>
        """
    
    html += """
    </body>
    </html>
    """
    
    with open(output_html, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"âœ… ë¦¬ë·° í˜ì´ì§€ ìƒì„±: {output_html}")
    print(f"   ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ 10ê°œ ìƒ˜í”Œë§Œ ê²€í† í•˜ì„¸ìš” (5ë¶„ ì†Œìš”)")
```

#### Step 3: ê°„ë‹¨í•œ ì •í™•ë„ ì¶”ì •

```python
# 10ê°œ ìƒ˜í”Œ ì¤‘ 7ê°œ ì •í™• â†’ 70% ì •í™•ë„ ì¶”ì •
estimated_accuracy = correct_count / total_samples
```

### ì¥ì 
- âœ… ë¹ ë¥¸ ê²€ì¦ (10ë¶„ ì´ë‚´)
- âœ… ì¸ê°„ì˜ ì§ê´€ í™œìš©
- âœ… ê·¹ë‹¨ì  ì˜¤ë¥˜ íƒì§€

### ë‹¨ì 
- âŒ í†µê³„ì  ìœ ì˜ì„± ë‚®ìŒ
- âŒ ì£¼ê´€ì 

---

## âœ… ë°©ë²• 5: External Benchmark Correlation (ì™¸ë¶€ ë²¤ì¹˜ë§ˆí¬ ìƒê´€ê´€ê³„)

### ì›ë¦¬
ì´ë¯¸ ê²€ì¦ëœ **ê³µê°œ ë°ì´í„°ì…‹ ì ìˆ˜**ì™€ í”„ë¡œì íŠ¸ ë°ì´í„° ê°„ ìƒê´€ê´€ê³„ ì¶”ì •

### êµ¬í˜„

#### Step 1: ê³µê°œ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ì§‘

```python
# ê° ëª¨ë¸ì˜ ë…¼ë¬¸/HuggingFace í˜ì´ì§€ì—ì„œ ê³µê°œëœ ì •í™•ë„
external_benchmarks = {
    'superb/wav2vec2-large-superb-er': {
        'IEMOCAP': 0.65,
        'RAVDESS': 0.72
    },
    'speechbrain/emotion-recognition-wav2vec2-IEMOCAP': {
        'IEMOCAP': 0.79
    }
}
```

#### Step 2: ìƒê´€ ë¶„ì„

```python
def estimate_performance(model_name, cross_consistency, external_benchmarks):
    """ì™¸ë¶€ ë²¤ì¹˜ë§ˆí¬ì™€ ì¼ì¹˜ë„ë¥¼ ê²°í•©í•œ ì„±ëŠ¥ ì¶”ì •"""
    
    # ì™¸ë¶€ ë²¤ì¹˜ë§ˆí¬ í‰ê· 
    if model_name in external_benchmarks:
        external_avg = np.mean(list(external_benchmarks[model_name].values()))
    else:
        external_avg = 0.6  # ê¸°ë³¸ê°’
    
    # êµì°¨ ì¼ì¹˜ë„ì™€ ì™¸ë¶€ ë²¤ì¹˜ë§ˆí¬ ê°€ì¤‘ í‰ê· 
    estimated_accuracy = 0.6 * cross_consistency + 0.4 * external_avg
    
    return estimated_accuracy
```

---

## ğŸ“Š í†µí•© í‰ê°€ í”„ë ˆì„ì›Œí¬

ëª¨ë“  ë°©ë²•ì„ ê²°í•©í•œ ìµœì¢… í‰ê°€ ìŠ¤í¬ë¦½íŠ¸:

```python
class UnsupervisedEvaluator:
    """ë¼ë²¨ ì—†ì´ ëª¨ë¸ í’ˆì§ˆ í‰ê°€"""
    
    def __init__(self, models):
        self.models = models
        self.predictions = {}
    
    def evaluate(self, video_path):
        # 1. ëª¨ë“  ëª¨ë¸ë¡œ ì˜ˆì¸¡
        for model_name in self.models:
            classifier = EmotionClassifier(audio_model_name=model_name)
            self.predictions[model_name] = classifier.classify_video(video_path)
        
        # 2. êµì°¨ ì¼ì¹˜ë„ ê³„ì‚°
        consistency = calculate_consistency(self.predictions)
        
        # 3. ê° ëª¨ë¸ë³„ í’ˆì§ˆ ì§€í‘œ
        quality_scores = {}
        for model_name, preds in self.predictions.items():
            confidence_metrics = analyze_confidence(preds)
            distribution_metrics = analyze_emotion_distribution(preds)
            entropy_score, _ = calculate_entropy_score(preds)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            overall_score = (
                0.3 * consistency.get(model_name, 0.5) +
                0.3 * entropy_score +
                0.2 * (1 - distribution_metrics['neutral_ratio']) +  # ì¤‘ë¦½ íŒ¨ë„í‹°
                0.2 * confidence_metrics['mean_confidence']
            )
            
            quality_scores[model_name] = {
                'overall_score': overall_score,
                'consistency': consistency.get(model_name, 0),
                'entropy_quality': entropy_score,
                'neutral_ratio': distribution_metrics['neutral_ratio'],
                'mean_confidence': confidence_metrics['mean_confidence'],
                'diversity': distribution_metrics['diversity']
            }
        
        # 4. ìˆœìœ„ ë§¤ê¸°ê¸°
        ranked = sorted(quality_scores.items(), key=lambda x: x[1]['overall_score'], reverse=True)
        
        return ranked
```

### ì‚¬ìš© ì˜ˆì‹œ

```python
# ë¼ë²¨ ì—†ì´ ëª¨ë¸ í‰ê°€
evaluator = UnsupervisedEvaluator([
    'superb/wav2vec2-large-superb-er',
    'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition',
    'speechbrain/emotion-recognition-wav2vec2-IEMOCAP'
])

ranked_models = evaluator.evaluate('assets/simpson.mp4')

for rank, (model, scores) in enumerate(ranked_models, 1):
    print(f"{rank}. {model}")
    print(f"   Overall Score: {scores['overall_score']:.3f}")
    print(f"   Consistency: {scores['consistency']:.3f}")
    print(f"   Entropy Quality: {scores['entropy_quality']:.3f}")
    print(f"   Neutral Ratio: {scores['neutral_ratio']:.3f}")
    print()
```

---

## ğŸ“ˆ ì‹¤ì œ í”„ë¡œì íŠ¸ ì ìš© ì˜ˆì‹œ

### Simpson ë°ì´í„°ì…‹ (ë¼ë²¨ ìˆìŒ) vs ìƒˆ ì˜ìƒ (ë¼ë²¨ ì—†ìŒ)

#### ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤

1. **Simpsonìœ¼ë¡œ supervised í‰ê°€** (Ground Truth)
```python
supervised_accuracy = evaluate_with_labels('assets/simpson.mp4', 'labelled_simpson.jsonl')
# superb: 0.645
```

2. **Simpsonìœ¼ë¡œ unsupervised í‰ê°€** (ë¼ë²¨ ìˆ¨ê¹€)
```python
unsupervised_score = evaluator.evaluate('assets/simpson.mp4')
# superb: 0.687 (overall score)
```

3. **ìƒê´€ê´€ê³„ í™•ì¸**
```python
correlation = np.corrcoef([supervised_accuracy], [unsupervised_score])[0, 1]
# 0.85 ì´ìƒì´ë©´ ì‹ ë¢° ê°€ëŠ¥
```

4. **ìƒˆ ì˜ìƒì— ì ìš©**
```python
# ì´ì œ ë¼ë²¨ ì—†ëŠ” ìƒˆ ì˜ìƒë„ unsupervised ë°©ì‹ìœ¼ë¡œ í‰ê°€ ê°€ëŠ¥
new_video_scores = evaluator.evaluate('assets/new_movie.mp4')
```

---

## âœ… ì¶”ì²œ ì „ëµ

### ì‹¤ì „ í”„ë¡œí† ì½œ

1. **Simpson ë°ì´í„°ì…‹ (ë¼ë²¨ ìˆìŒ)**:
   - Supervised í‰ê°€ë¡œ ì ˆëŒ€ ì •í™•ë„ ì¸¡ì •
   - ìƒìœ„ 3ê°œ ëª¨ë¸ ì„ ì •

2. **ìƒˆ ì˜ìƒ 10ê°œ (ë¼ë²¨ ì—†ìŒ)**:
   - Unsupervised í‰ê°€ë¡œ ì¼ê´€ì„± í™•ì¸
   - Simpsonê³¼ ë™ì¼í•œ ìˆœìœ„ ìœ ì§€í•˜ëŠ”ì§€ ê²€ì¦

3. **ìµœì¢… ëª¨ë¸ ì„ íƒ**:
   - ë‘ í‰ê°€ì—ì„œ ëª¨ë‘ ìƒìœ„ê¶Œ ëª¨ë¸ ì„ íƒ
   - ì‹ ë¢°ë„ 95% ì´ìƒ

### ìµœì†Œ ì‘ì—…ëŸ‰

- **ë¼ë²¨ë§**: Simpsonë§Œ (31ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì´ë¯¸ ì™„ë£Œ)
- **Unsupervised í‰ê°€**: ìë™ (ë¼ë²¨ ë¶ˆí•„ìš”)
- **ìµœì¢… ê²€ì¦**: 10ê°œ ìƒ˜í”Œë§Œ ìˆ˜ë™ í™•ì¸ (10ë¶„)

---

## ìš”ì•½

| ë°©ë²• | ë¼ë²¨ í•„ìš” | ì†Œìš” ì‹œê°„ | ì‹ ë¢°ë„ | ì‚¬ìš© ì‹œì  |
|------|----------|----------|--------|-----------|
| **Cross-Model Consistency** | âŒ | ìë™ | â­â­â­â­ | ê¸°ë³¸ í‰ê°€ |
| **Confidence Analysis** | âŒ | ìë™ | â­â­â­ | í’ˆì§ˆ ì§„ë‹¨ |
| **Entropy Score** | âŒ | ìë™ | â­â­â­â­ | ì •ëŸ‰ í‰ê°€ |
| **Perceptual Validation** | âŒ | 10ë¶„ | â­â­â­â­â­ | ìµœì¢… ê²€ì¦ |
| **External Benchmark** | âŒ | ìë™ | â­â­â­ | ë³´ì¡° ì§€í‘œ |
| **Supervised (Ground Truth)** | âœ… | 1ì‹œê°„+ | â­â­â­â­â­ | ì ˆëŒ€ ê¸°ì¤€ |

**ê¶Œì¥ ì¡°í•©**: 
1. Simpsonìœ¼ë¡œ Supervised í‰ê°€ (1íšŒ)
2. ëª¨ë“  ì˜ìƒì— Unsupervised í‰ê°€ ì ìš©
3. 10ê°œ ìƒ˜í”Œë¡œ Perceptual Validation (ìµœì¢… í™•ì¸)

ì´ ë°©ì‹ìœ¼ë¡œ **ë¼ë²¨ë§ ì‹œê°„ 90% ì ˆê°** ê°€ëŠ¥í•©ë‹ˆë‹¤!
