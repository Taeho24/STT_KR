# ì´ í”„ë¡œì íŠ¸ì— ì í•©í•œ ëª¨ë¸ ì„ ì • ê¸°ì¤€

## í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„

### í•µì‹¬ ê¸°ëŠ¥
- **ì…ë ¥**: ì˜ìƒ íŒŒì¼ (í•œêµ­ì–´/ì˜ì–´ ìŒì„±)
- **ì²˜ë¦¬**: WhisperX STT â†’ ê°ì • ë¶„ë¥˜ â†’ ìŠ¤íƒ€ì¼ë§ëœ ASS ìë§‰ ìƒì„±
- **ì¶œë ¥**: ê°ì •ë³„ ìƒ‰ìƒ/í°íŠ¸ ì ìš©ëœ ìë§‰ íŒŒì¼ (.ass/.srt)

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- ì˜í™”, ë“œë¼ë§ˆ, ìœ íŠœë¸Œ ì˜ìƒì— ê°ì • í‘œí˜„ ìë§‰ ì¶”ê°€
- ë°°ì¹˜ ì²˜ë¦¬ (ì‹¤ì‹œê°„ ì•„ë‹˜)
- ê¸´ ì˜ìƒë„ ì²˜ë¦¬ ê°€ëŠ¥í•´ì•¼ í•¨ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)

---

## âœ… í•„ìˆ˜ ì¡°ê±´ (Must-Have)

### 1. **7ê°œ ê°ì • í´ë˜ìŠ¤ ì§€ì›**
í”„ë¡œì íŠ¸ì˜ `config.py`ì— ì •ì˜ëœ ê°ì •:
```python
'neutral', 'happy', 'sad', 'angry', 'fear', 'surprise', 'disgust'
```

**ì œì™¸ ê¸°ì¤€**:
- âŒ 4ê°œ ì´í•˜ ê°ì • (angry, happy, sad, neutralë§Œ ì§€ì›)
- âŒ ì°¨ì› ê¸°ë°˜ ì¶œë ¥ (arousal/valence/dominance)
- âŒ ë°”ì´ë„ˆë¦¬ ë¶„ë¥˜ (positive/negative)

**í—ˆìš©**:
- âœ… 7ê°œ ì •í™•íˆ ì¼ì¹˜
- âœ… 8ê°œ ì´ìƒ (ë§¤í•‘ ê°€ëŠ¥: calm â†’ neutral)

---

### 2. **ì˜¤ë””ì˜¤ ì…ë ¥ ì§€ì›**
**í˜„ì¬ íŒŒì´í”„ë¼ì¸**:
```python
audio_segment = librosa.load(audio_path, sr=16000)
emotion = classifier.predict(audio_segment)
```

**ì œì™¸ ê¸°ì¤€**:
- âŒ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸ (DistilRoBERTa, BERT, GPT)
- âŒ ì´ë¯¸ì§€ ì…ë ¥ (ì–¼êµ´ í‘œì • ì¸ì‹)
- âŒ ë©€í‹°ëª¨ë‹¬ í•„ìˆ˜ (ì˜¤ë””ì˜¤+ë¹„ë””ì˜¤ ë™ì‹œ í•„ìš”)

**í—ˆìš©**:
- âœ… ìˆœìˆ˜ ì˜¤ë””ì˜¤ ëª¨ë¸ (Wav2Vec2, HuBERT, WavLM)
- âœ… íŠ¹ì§• ì¶”ì¶œ + ë¶„ë¥˜ê¸° (OpenSMILE + SVM)
- âœ… ë©€í‹°ëª¨ë‹¬ ì„ íƒì  (ì˜¤ë””ì˜¤ë§Œìœ¼ë¡œë„ ì‘ë™)

---

### 3. **ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´ + ì˜ì–´)**
**ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­**:
> "ì˜ì–´ì™€ í•œêµ­ì–´ ëª¨ë‘ ì…ë ¥ ê°€ëŠ¥í•˜ê²Œ í• ê±°ê³ "

**ìš°ì„ ìˆœìœ„**:
1. ğŸ¥‡ **í•œêµ­ì–´ + ì˜ì–´ ë™ì‹œ ì§€ì›** (XLS-R ê¸°ë°˜)
2. ğŸ¥ˆ **ì˜ì–´ ì „ìš© (í•œêµ­ì–´ ì „ì´ ê°€ëŠ¥)** (ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ í•™ìŠµ)
3. ğŸ¥‰ **í•œêµ­ì–´ ì „ìš©** (jungjongho ëª¨ë¸)

**ì œì™¸ ê¸°ì¤€**:
- âŒ íŠ¹ì • ì–¸ì–´ ì „ìš© (ê·¸ë¦¬ìŠ¤ì–´, ë…ì¼ì–´ë§Œ)
- âŒ ì˜ì–´ì—ì„œ í•œêµ­ì–´ ì „ì´ ì„±ëŠ¥ 0ì— ê°€ê¹Œì›€

---

### 4. **HuggingFace Transformers í˜¸í™˜ì„± (ìš°ì„ )**
**í˜„ì¬ ë¡œë”© ë°©ì‹**:
```python
model = AutoModelForAudioClassification.from_pretrained(model_name)
feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
```

**ìš°ì„ ìˆœìœ„**:
- ğŸ¥‡ **Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§ì ‘ ì§€ì›** (ì¦‰ì‹œ í†µí•©)
- ğŸ¥ˆ **Adapter íŒ¨í„´ìœ¼ë¡œ í†µí•© ê°€ëŠ¥** (SpeechBrain, TensorFlow)
- ğŸ¥‰ **ìˆ˜ë™ í†µí•© í•„ìš”** (OpenSMILE, Kaggle ëª¨ë¸)

**ì œì™¸ ê¸°ì¤€**:
- âŒ íì‡„í˜• API (OpenAI, Google Cloud - ë¹„ìš© ë°œìƒ)
- âŒ ì˜¨ë¼ì¸ ì „ìš© (ì˜¤í”„ë¼ì¸ ì‚¬ìš© ë¶ˆê°€)
- âŒ ìƒìš© ë¼ì´ì„ ìŠ¤ (MIT/Apache ì„ í˜¸)

---

### 5. **ë°°ì¹˜ ì²˜ë¦¬ íš¨ìœ¨ì„±**
**í˜„ì¬ ì½”ë“œ**:
```python
def classify_batch(self, segments: List[dict], batch_size: int = 4):
    for i in range(0, len(segments), batch_size):
        batch = segments[i:i + batch_size]
        # ë°°ì¹˜ ì²˜ë¦¬
```

**ìš”êµ¬ì‚¬í•­**:
- âœ… ê¸´ ì˜ìƒ ì²˜ë¦¬ (30ë¶„~2ì‹œê°„)
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (8GB GPUì—ì„œ ì‘ë™)
- âœ… ì¶”ë¡  ì†ë„ í•©ë¦¬ì  (ì‹¤ì‹œê°„ì˜ 10ë°° ì´ë‚´)

**ì œì™¸ ê¸°ì¤€**:
- âŒ ì´ˆëŒ€í˜• ëª¨ë¸ (10GB+ ë©”ëª¨ë¦¬ í•„ìš”)
- âŒ ì„¸ê·¸ë¨¼íŠ¸ë‹¹ 5ì´ˆ ì´ìƒ ì²˜ë¦¬ ì‹œê°„
- âŒ ë°°ì¹˜ ì²˜ë¦¬ ë¯¸ì§€ì› (ì„¸ê·¸ë¨¼íŠ¸ë§ˆë‹¤ ì¬ë¡œë”©)

---

## ğŸ¯ ê°€ì‚°ì  ì¡°ê±´ (Nice-to-Have)

### 1. **ë†’ì€ ì •í™•ë„** (Simpson ë°ì´í„°ì…‹ ê¸°ì¤€)
- ğŸ¥‡ **Accuracy > 0.6** (í˜„ì¬ 1ìœ„: superb 0.645)
- ğŸ¥ˆ **Macro F1 > 0.3** (ê°ì • ê· í˜• ê³ ë ¤)
- ğŸ¥‰ **Neutral Rate < 50%** (ì¤‘ë¦½ í¸í–¥ ë°©ì§€)

### 2. **ìµœì‹  ì•„í‚¤í…ì²˜**
- Wav2Vec2 XLS-R (ë‹¤êµ­ì–´)
- Whisper Encoder (ìŒì„± í‘œí˜„ ê°•ë ¥)
- Transformer + CNN Hybrid

### 3. **ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ì œê³µ**
- IEMOCAP (ì—°ê¸° ê°ì •)
- RAVDESS (ê°ì • ìŒì„±)
- MSP-Podcast (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”)

### 4. **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°**
- HuggingFace ë‹¤ìš´ë¡œë“œ 1000íšŒ ì´ìƒ
- GitHub Stars 100ê°œ ì´ìƒ
- ìµœê·¼ 1ë…„ ë‚´ ì—…ë°ì´íŠ¸

---

## âŒ ì œì™¸ ê¸°ì¤€ (Exclusion Criteria)

### ìë™ ì œì™¸ ëŒ€ìƒ

#### 1. **ê°ì • í´ë˜ìŠ¤ ë¶ˆì¼ì¹˜**
- `audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim`
  - ì´ìœ : arousal/valence/dominance ì¶œë ¥ (ì°¨ì› ê¸°ë°˜)
  - ì˜í–¥: 7ê°œ ê°ì •ìœ¼ë¡œ ë§¤í•‘ ë¶ˆê°€ëŠ¥

#### 2. **ì–¸ì–´ ë¯¸ì§€ì›**
- `m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition`
  - ì´ìœ : ê·¸ë¦¬ìŠ¤ì–´ ì „ìš©, ì˜ì–´ ì „ì´ ì‹¤íŒ¨ (0.032 ì •í™•ë„)
  - ì˜í–¥: í•œêµ­ì–´/ì˜ì–´ ì²˜ë¦¬ ë¶ˆê°€

#### 3. **í˜•ì‹ ë¹„í˜¸í™˜ (ìˆ˜ë™ ì œì™¸)**
- êµ¬ì¡°ì  ë¹„í˜¸í™˜: `config.json` ì—†ìŒ
- ë¡œë”© ì‹¤íŒ¨: Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì§€ì›

#### 4. **ê·¹ë‹¨ì  í¸í–¥**
- `harshit345/xlsr-wav2vec-speech-emotion-recognition`
  - ì´ìœ : 100% sad ì˜ˆì¸¡ (Simpson ë°ì´í„°ì…‹)
  - ì˜í–¥: ì‹¤ìš©ì„± ì—†ìŒ

#### 5. **ë¼ì´ì„ ìŠ¤ ë¬¸ì œ**
- ìƒìš© ë¼ì´ì„ ìŠ¤ (ì¬ë°°í¬ ë¶ˆê°€)
- í•™ìˆ  ì „ìš© (ìƒì—…ì  ì‚¬ìš© ê¸ˆì§€)

---

## ğŸ“Š í˜„ì¬ í›„ë³´êµ° í‰ê°€

### Tier S: ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥ + ê³ ì„±ëŠ¥
1. âœ… **superb/wav2vec2-large-superb-er**
   - ì •í™•ë„: 0.645, F1: 0.211
   - 7ê°œ ê°ì • ì™„ë²½ ì§€ì›
   - ì˜ì–´ ê¸°ë°˜ (í•œêµ­ì–´ ì „ì´ ê°€ëŠ¥)

2. âœ… **marcogdepinto/emotion-recognition-using-voice** (GitHub)
   - 7ê°œ ê°ì •
   - scikit-learn ê¸°ë°˜ (CPU íš¨ìœ¨ì )
   - RAVDESS í•™ìŠµ

### Tier A: í†µí•© í•„ìš” + ì ì¬ë ¥ ë†’ìŒ
3. ğŸ”„ **speechbrain/emotion-recognition-wav2vec2-IEMOCAP**
   - Adapter í•„ìš”
   - IEMOCAP ì‚¬ì „ í•™ìŠµ (ì—°ê¸° ê°ì •)

4. ğŸ”„ **IliaZenkov/transformer-cnn-emotion-recognition** (GitHub)
   - Transformer + CNN
   - 6ê°œ ê°ì • (ë§¤í•‘ í•„ìš”)

### Tier B: í•œêµ­ì–´ íŠ¹í™”
5. âš ï¸ **jungjongho/wav2vec2-xlsr-korean-speech-emotion-recognition**
   - í•œêµ­ì–´ ì „ìš© (ì˜ì–´ 0.065 ì •í™•ë„)
   - í•œêµ­ì–´ ë°ì´í„°ì…‹ìœ¼ë¡œë§Œ í‰ê°€í•´ì•¼ í•¨

### Tier C: ì œì™¸
- âŒ ehcalabres (100% neutral)
- âŒ audeering (ì°¨ì› ê¸°ë°˜ ì¶œë ¥)
- âŒ harshit345 (100% sad)
- âŒ m3hrdadfi (ê·¸ë¦¬ìŠ¤ì–´ ì „ìš©)

---

## ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ í›„ë³´êµ° (10ê°œ)

### HuggingFace (2ê°œ)
1. superb/wav2vec2-large-superb-er â­ (í˜„ì¬ 1ìœ„)
2. ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition (neutral í¸í–¥ ìˆ˜ì • ê°€ëŠ¥ ì‹œ)

### GitHub ì˜¤í”ˆì†ŒìŠ¤ (3ê°œ)
3. marcogdepinto/emotion-recognition-using-voice
4. IliaZenkov/transformer-cnn-emotion-recognition
5. MITESHPUTHRANNEU/Speech-Emotion-Analyzer

### SpeechBrain (1ê°œ)
6. speechbrain/emotion-recognition-wav2vec2-IEMOCAP

### Kaggle/TensorFlow (2ê°œ)
7. Kaggle RAVDESS ì‚¬ì „ í•™ìŠµ ëª¨ë¸
8. TensorFlow Hub YAMNet (ì „ì´ í•™ìŠµ)

### í•œêµ­ì–´ íŠ¹í™” (1ê°œ)
9. jungjongho/wav2vec2-xlsr-korean-speech-emotion-recognition

### OpenSMILE (1ê°œ)
10. OpenSMILE ComParE + SVM (í•™ìŠµ í•„ìš”)

---

## í‰ê°€ ì „ëµ

### 1ë‹¨ê³„: ì¦‰ì‹œ í‰ê°€ (HuggingFace + GitHub)
- ì†Œìš” ì‹œê°„: 2-3ì‹œê°„
- ëª¨ë¸ ìˆ˜: 5ê°œ
- ëª©í‘œ: í˜„ì¬ 1ìœ„ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ í›„ë³´ ë°œê²¬

### 2ë‹¨ê³„: ê³ ê¸‰ í†µí•© (SpeechBrain + Kaggle)
- ì†Œìš” ì‹œê°„: 3-4ì‹œê°„
- ëª¨ë¸ ìˆ˜: 3ê°œ
- ëª©í‘œ: ìµœì‹  ì•„í‚¤í…ì²˜ ì„±ëŠ¥ ê²€ì¦

### 3ë‹¨ê³„: í•œêµ­ì–´ ë°ì´í„°ì…‹ í‰ê°€
- ì†Œìš” ì‹œê°„: 2-3ì‹œê°„
- ëª¨ë¸ ìˆ˜: jungjongho + Top 3 ëª¨ë¸
- ëª©í‘œ: í•œêµ­ì–´ ì„±ëŠ¥ í™•ì¸

---

## ìš”ì•½

**ì í•©í•œ ëª¨ë¸ = 7ê°œ ê°ì • + ì˜¤ë””ì˜¤ ì…ë ¥ + ë‹¤êµ­ì–´ ì§€ì› + Transformers í˜¸í™˜ + ë°°ì¹˜ ì²˜ë¦¬ íš¨ìœ¨**

**ìµœìš°ì„  í…ŒìŠ¤íŠ¸ ëŒ€ìƒ**:
1. marcogdepinto (GitHub, ì¦‰ì‹œ ì‚¬ìš©)
2. speechbrain IEMOCAP (ê³ ì„±ëŠ¥ ê¸°ëŒ€)
3. Kaggle RAVDESS (ê²€ì¦ëœ ë°ì´í„°ì…‹)

ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì‹œê² ìŠµë‹ˆê¹Œ?
