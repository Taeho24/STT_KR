#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìë™ ëª¨ë¸ í›„ë³´ ì¼ê´„ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- ë ˆì´ë¸” ìˆëŠ” í‰ê°€ (Simpson)
- ë ˆì´ë¸” ì—†ëŠ” í‰ê°€ (Cross-model consistency)
- ì†ë„ ë²¤ì¹˜ë§ˆí¬
"""

import argparse
import json
import time
import subprocess
from pathlib import Path
from typing import List, Dict
import pandas as pd

# configì—ì„œ í›„ë³´ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from config import config

def run_supervised_evaluation(video_path: str, labels_path: str, model: str, device: str = "auto") -> Dict:
    """ë ˆì´ë¸” ê¸°ë°˜ í‰ê°€ ì‹¤í–‰"""
    cmd = [
        sys.executable,
        "tools/model_evaluator.py",
        "--video", video_path,
        "--labels", labels_path,
        "--disable-text",
        "--audio-models", model,
        "--device", device
    ]
    
    print(f"\n{'='*80}")
    print(f"ğŸ”„ Evaluating: {model}")
    print(f"{'='*80}")
    
    start_time = time.time()
    
    try:
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            timeout=600,
            encoding='utf-8',
            errors='replace'
        )
        elapsed = time.time() - start_time
        
        if result.returncode == 0:
            # ì¶œë ¥ì—ì„œ ê²°ê³¼ íŒŒì‹±
            output = result.stdout
            
            # Accuracy ì¶”ì¶œ
            accuracy = None
            macro_f1 = None
            neutral_rate = None
            
            for line in output.split('\n'):
                if 'Accuracy:' in line:
                    try:
                        accuracy = float(line.split(':')[1].strip())
                    except:
                        pass
                elif 'Macro F1:' in line:
                    try:
                        macro_f1 = float(line.split(':')[1].strip())
                    except:
                        pass
                elif 'Neutral Rate:' in line or 'neutral prediction rate' in line.lower():
                    try:
                        neutral_rate = float(line.split(':')[1].strip().replace('%', ''))
                    except:
                        pass
            
            return {
                'model': model,
                'status': 'success',
                'accuracy': accuracy,
                'macro_f1': macro_f1,
                'neutral_rate': neutral_rate,
                'elapsed_time': elapsed,
                'output': output
            }
        else:
            return {
                'model': model,
                'status': 'failed',
                'error': result.stderr,
                'elapsed_time': elapsed
            }
    
    except subprocess.TimeoutExpired:
        return {
            'model': model,
            'status': 'timeout',
            'elapsed_time': 600
        }
    except Exception as e:
        return {
            'model': model,
            'status': 'error',
            'error': str(e),
            'elapsed_time': time.time() - start_time
        }

def main():
    parser = argparse.ArgumentParser(description="ëª¨ë¸ í›„ë³´ ì¼ê´„ í‰ê°€")
    parser.add_argument("--video", type=str, default="assets/simpson.mp4", help="í‰ê°€ ì˜ìƒ")
    parser.add_argument("--labels", type=str, default="labelled_simpson.jsonl", help="ë ˆì´ë¸” íŒŒì¼")
    parser.add_argument("--device", type=str, default="auto", help="ë””ë°”ì´ìŠ¤")
    parser.add_argument("--output", type=str, default="result/batch_evaluation.json", help="ê²°ê³¼ ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--models", nargs="+", help="í‰ê°€í•  ëª¨ë¸ (ê¸°ë³¸: configì˜ audio_candidates)")
    
    args = parser.parse_args()
    
    # ëª¨ë¸ ëª©ë¡
    if args.models:
        models = args.models
    else:
        models = config.get('models', 'audio_candidates', [])
    
    print(f"\nğŸ“‹ ì´ {len(models)}ê°œ ëª¨ë¸ í‰ê°€ ì‹œì‘")
    print(f"   ì˜ìƒ: {args.video}")
    print(f"   ë ˆì´ë¸”: {args.labels}")
    print(f"   ë””ë°”ì´ìŠ¤: {args.device}")
    
    # í‰ê°€ ì‹¤í–‰
    results = []
    for i, model in enumerate(models, 1):
        print(f"\n[{i}/{len(models)}] {model}")
        result = run_supervised_evaluation(args.video, args.labels, model, args.device)
        results.append(result)
        
        # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
        if result['status'] == 'success':
            print(f"   âœ… Accuracy: {result.get('accuracy', 'N/A')}")
            print(f"   âœ… Macro F1: {result.get('macro_f1', 'N/A')}")
            print(f"   â±ï¸  Time: {result['elapsed_time']:.1f}s")
        else:
            print(f"   âŒ Status: {result['status']}")
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path(args.output)
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    
    # ìˆœìœ„í‘œ ìƒì„±
    print(f"\n{'='*80}")
    print("ğŸ“Š í‰ê°€ ê²°ê³¼ ìˆœìœ„")
    print(f"{'='*80}")
    
    # ì„±ê³µí•œ ëª¨ë¸ë§Œ í•„í„°ë§
    successful = [r for r in results if r['status'] == 'success' and r.get('accuracy') is not None]
    
    if not successful:
        print("âš ï¸  í‰ê°€ì— ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìˆœìœ„ ì •ë ¬ (ì •í™•ë„ ìš°ì„ , ì†ë„ ë³´ì¡°)
    successful.sort(key=lambda x: (x.get('accuracy', 0), -x.get('elapsed_time', 999)), reverse=True)
    
    print(f"\n{'Rank':<6}{'Model':<60}{'Acc':<8}{'F1':<8}{'Neutral':<10}{'Time(s)':<8}")
    print("-" * 100)
    
    for i, result in enumerate(successful, 1):
        model_short = result['model'].split('/')[-1][:55]
        acc = result.get('accuracy', 0)
        f1 = result.get('macro_f1', 0)
        neutral = result.get('neutral_rate', 0)
        elapsed = result.get('elapsed_time', 0)
        
        print(f"{i:<6}{model_short:<60}{acc:<8.3f}{f1:<8.3f}{neutral:<10.3f}{elapsed:<8.1f}")
    
    # ì‹¤íŒ¨í•œ ëª¨ë¸
    failed = [r for r in results if r['status'] != 'success']
    if failed:
        print(f"\nâŒ ì‹¤íŒ¨í•œ ëª¨ë¸ ({len(failed)}ê°œ):")
        for r in failed:
            print(f"   - {r['model']}: {r['status']}")
    
    # CSV ì €ì¥
    csv_path = output_path.with_suffix('.csv')
    df = pd.DataFrame(successful)
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ“Š CSV ì €ì¥: {csv_path}")
    
    # ìµœê³  ëª¨ë¸ ì¶”ì²œ
    if successful:
        best = successful[0]
        print(f"\nğŸ† ìµœê³  ëª¨ë¸: {best['model']}")
        print(f"   ì •í™•ë„: {best.get('accuracy', 0):.3f}")
        print(f"   F1 Score: {best.get('macro_f1', 0):.3f}")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {best.get('elapsed_time', 0):.1f}s")
        
        # config ì—…ë°ì´íŠ¸ ì œì•ˆ
        print(f"\nğŸ’¡ config.py ì—…ë°ì´íŠ¸ ì¶”ì²œ:")
        print(f"   'audio': '{best['model']}'")

if __name__ == "__main__":
    main()
